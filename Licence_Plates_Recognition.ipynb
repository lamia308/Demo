{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCMJFoJoyMr1jCEX26F1br",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamia308/Demo/blob/master/Licence_Plates_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "PqXvRvmJXSx4",
        "outputId": "bd4f8183-7aa1-4964-a6ce-e818d914aa44"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f546358c1bc0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load YOLOv4 configuration and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov4.cfg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yolov4.weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load class names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/dnn/src/darknet/darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov4.cfg in function 'readNetFromDarknet'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load YOLOv4 configuration and weights\n",
        "net = cv2.dnn.readNet(\"yolov4.cfg\", \"yolov4.weights\")\n",
        "\n",
        "# Load class names\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Set input image size\n",
        "input_size = (608, 608)\n",
        "\n",
        "# Load image\n",
        "image = cv2.imread(\"image.jpg\")\n",
        "\n",
        "# Resize image to input size\n",
        "resized_image = cv2.resize(image, input_size)\n",
        "\n",
        "# Normalize image and convert it to blob\n",
        "blob = cv2.dnn.blobFromImage(resized_image, 1 / 255.0, input_size, swapRB=True, crop=False)\n",
        "\n",
        "# Set the input blob for the network\n",
        "net.setInput(blob)\n",
        "\n",
        "# Perform forward pass\n",
        "outputs = net.forward()\n",
        "\n",
        "# Filter out the bounding boxes with confidence score above threshold\n",
        "conf_threshold = 0.5\n",
        "nms_threshold = 0.4\n",
        "\n",
        "boxes = []\n",
        "confidences = []\n",
        "class_ids = []\n",
        "\n",
        "for output in outputs:\n",
        "    for detection in output:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "\n",
        "        if confidence > conf_threshold and class_id == 2:\n",
        "            center_x = int(detection[0] * input_size[0])\n",
        "            center_y = int(detection[1] * input_size[1])\n",
        "            width = int(detection[2] * input_size[0])\n",
        "            height = int(detection[3] * input_size[1])\n",
        "\n",
        "            x = int(center_x - width / 2)\n",
        "            y = int(center_y - height / 2)\n",
        "\n",
        "            boxes.append([x, y, width, height])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)\n",
        "\n",
        "# Apply non-maxima suppression to remove overlapping bounding boxes\n",
        "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "# Iterate over the remaining indices\n",
        "for i in indices:\n",
        "    i = i[0]\n",
        "    box = boxes[i]\n",
        "    x, y, w, h = box[0], box[1], box[2], box[3]\n",
        "\n",
        "    # Draw bounding box and display class label\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    cv2.putText(image, classes[class_ids[i]], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Display the result\n",
        "cv2.imshow(\"Vehicle Number Plate Detection\", image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load YOLOv4 configuration and weights\n",
        "net = cv2.dnn.readNet(\"yolov4.cfg\", \"yolov4.weights\")\n",
        "\n",
        "# Load class names\n",
        "with open(\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Set input image size\n",
        "input_size = (608, 608)\n",
        "\n",
        "# Function to perform object detection on image\n",
        "def detect_objects_image(image):\n",
        "    # Resize image to input size\n",
        "    resized_image = cv2.resize(image, input_size)\n",
        "\n",
        "    # Normalize image and convert it to blob\n",
        "    blob = cv2.dnn.blobFromImage(resized_image, 1 / 255.0, input_size, swapRB=True, crop=False)\n",
        "\n",
        "    # Set the input blob for the network\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # Perform forward pass\n",
        "    outputs = net.forward()\n",
        "\n",
        "    # Filter out the bounding boxes with confidence score above threshold\n",
        "    conf_threshold = 0.5\n",
        "    nms_threshold = 0.4\n",
        "\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    class_ids = []\n",
        "\n",
        "    for output in outputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "\n",
        "            if confidence > conf_threshold and class_id == 2:\n",
        "                center_x = int(detection[0] * input_size[0])\n",
        "                center_y = int(detection[1] * input_size[1])\n",
        "                width = int(detection[2] * input_size[0])\n",
        "                height = int(detection[3] * input_size[1])\n",
        "\n",
        "                x = int(center_x - width / 2)\n",
        "                y = int(center_y - height / 2)\n",
        "\n",
        "                boxes.append([x, y, width, height])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Apply non-maxima suppression to remove overlapping bounding boxes\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "    # Iterate over the remaining indices\n",
        "    for i in indices:\n",
        "        i = i[0]\n",
        "        box = boxes[i]\n",
        "        x, y, w, h = box[0], box[1], box[2], box[3]\n",
        "\n",
        "        # Draw bounding box and display class label\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(image, classes[class_ids[i]], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Function to perform object detection on video\n",
        "def detect_objects_video(video_path):\n",
        "    # Open video file\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get video dimensions\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Create output video writer\n",
        "    output_video = cv2.VideoWriter(\"output.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Perform object detection on frame\n",
        "        detected_frame = detect_objects_image(frame)\n",
        "\n",
        "        # Write the detected frame to the output video\n",
        "        output_video.write(detected_frame)\n",
        "\n",
        "        # Display the resulting frame\n",
        "        cv2.imshow(\"Vehicle Number Plate Detection\", detected_frame)\n",
        "\n",
        "        if cv2.waitKey(1) == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    # Release video capture and writer\n",
        "    video.release()\n",
        "    output_video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Process image\n",
        "image = cv2.imread(\"image.jpg\")\n",
        "detected_image = detect_objects_image(image)\n",
        "cv2.imshow(\"Vehicle Number Plate Detection\", detected_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Process video\n",
        "video_path = \"video.mp4\"\n",
        "detect_objects_video()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "5TaLjHYtXevF",
        "outputId": "705d8b12-69b5-4674-d25e-9018a992aaea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-0e0c48cf7eb9>\"\u001b[0;36m, line \u001b[0;32m115\u001b[0m\n\u001b[0;31m    detect_objects_video(https://drive.google.com/drive/u/0/folders/1NrfuQwM8TP6kV-wsZHlQ0j3b-Axfs--Z)\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    }
  ]
}